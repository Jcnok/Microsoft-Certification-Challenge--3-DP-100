# Chatbot Inteligente com seus Pr√≥prios Documentos (PDF) üß†üí¨

Este projeto demonstra a cria√ß√£o de um chatbot interativo capaz de responder perguntas com base no **conte√∫do dos seus arquivos PDF** utilizando Intelig√™ncia Artificial Generativa e busca vetorial. Uma ferramenta poderosa para extrair informa√ß√µes espec√≠ficas de um conjunto de documentos! ‚ú®

## O Desafio üìöüîç

Imagine a dificuldade de gerenciar e extrair informa√ß√µes de uma grande quantidade de documentos, como artigos cient√≠ficos para um TCC, documentos como regulamentos, pol√≠ticas, contratos de trabalho, etc. Correlacionar ideias, encontrar pontos relevantes entre diferentes textos e estruturar uma pesquisa pode ser um processo demorado e complexo. ü§î

## A Solu√ß√£o com Intelig√™ncia Artificial üí°ü§ñ

Para enfrentar esse desafio, utilizamos a intelig√™ncia artificial para construir um sistema de busca inteligente. O objetivo √© permitir que um modelo de linguagem **interprete o conte√∫do dos seus PDFs**, organize essas informa√ß√µes e **gere respostas precisas e contextuais** para as suas perguntas, utilizando *apenas* o material que voc√™ carregou.

## Objetivos Alcan√ßados ‚úÖ

Neste projeto, voc√™ aprender√° a e demonstrar√° a capacidade de:

*   **Carregar** arquivos PDF contendo informa√ß√µes relevantes. üìÇ
*   Implementar um sistema de **busca vetorial** para indexar e recuperar informa√ß√µes de forma eficiente dos PDFs. üìä
*   Utilizar intelig√™ncia artificial para **gerar respostas** fundamentadas no conte√∫do dos documentos carregados. ‚úçÔ∏è
*   Desenvolver um **chat interativo** para fazer perguntas e obter respostas diretas e baseadas nos seus arquivos. üó£Ô∏è

## Como a M√°gica Acontece (Vis√£o T√©cnica) ‚ú®ü§ì

A arquitetura por tr√°s deste chatbot √© conhecida como **Retrieval Augmented Generation (RAG)**. O processo funciona assim:

1.  **Processamento de Documentos:** O conte√∫do dos PDFs √© dividido em peda√ßos menores.
2.  **Embeddings:** Cada peda√ßo de texto √© convertido em um **vetor num√©rico** (representando seu significado sem√¢ntico) usando um modelo de embedding.
3.  **Indexa√ß√£o Vetorial:** Esses vetores s√£o armazenados e indexados em um servi√ßo de busca vetorial (como o Azure AI Search), criando um √≠ndice pesquis√°vel dos seus documentos.
4.  **Ao Fazer uma Pergunta:** Sua pergunta √© convertida em um vetor.
5.  **Busca por Relev√¢ncia:** O sistema busca no √≠ndice vetorial os peda√ßos de texto dos seus documentos que s√£o mais semanticamente semelhantes √† sua pergunta.
6.  **Gera√ß√£o da Resposta:** Os trechos de texto mais relevantes encontrados s√£o usados como **contexto** para um modelo de linguagem generativo (como o GPT). O modelo, ent√£o, formula a resposta √† sua pergunta com base *exclusivamente* nesse contexto fornecido pelos seus documentos.

Esta abordagem permite que o chatbot responda com **informa√ß√µes altamente relevantes e espec√≠ficas** aos seus documentos carregados, o que √© ideal para pesquisa, an√°lise de dados internos ou qualquer cen√°rio onde voc√™ precise interagir com um conjunto de informa√ß√µes propriet√°rias. ‚öôÔ∏è

## Implementa√ß√£o com Azure AI Foundry üõ†Ô∏è‚òÅÔ∏è

Este projeto foi implementado utilizando a plataforma **Azure AI Foundry**. O Foundry facilita diversas etapas, incluindo:

*   Prepara√ß√£o do ambiente.
*   Deploy dos modelos de IA necess√°rios (modelos de embedding e modelos de chat).
*   Carregamento dos arquivos PDF.
*   Cria√ß√£o e gerenciamento do √≠ndice de busca vetorial.

A intera√ß√£o com o chatbot pode ser feita atrav√©s do **playground** da plataforma ou, como explorado no projeto, deployando-o como um **web app** para facilitar o acesso.

O Azure AI Foundry √© uma plataforma vers√°til que oferece muito mais do que apenas chatbots, incluindo servi√ßos para cria√ß√£o de agentes aut√¥nomos e fluxos de trabalho de IA (Prompt Flows). üöÄ

## Diagrama:
```mermaid
graph LR
    subgraph Ingest√£o e Indexa√ß√£o
        A[Documentos PDF] --> B(Processamento de Dados e Chunking);
        B --> C[Modelo de Embedding];
        C --> D{Azure AI Search √çndice Vetorial};
    end

    subgraph Fluxo de Consulta RAG
        E[Pergunta do Usu√°rio] --> F(Vetoriza√ß√£o da Pergunta);
        F --> C;
        F --> G(Busca Vetorial no √çndice);
        G --> D;
        D --> G;
        G --> H[Trechos Relevantes dos Documentos];
        E --> I(Modelo de Linguagem Generativa - LLM);
        H --> I;
        I --> J[Resposta Gerada e Contextualizada];
    end

    J --> E;
```
## Documenta√ß√£o da Arquitetura üìù

O diagrama acima representa o fluxo de dados e processos que permite ao chatbot responder perguntas com base nos seus arquivos PDF dentro do **Azure AI Foundry**. A arquitetura pode ser dividida em duas fases principais:

1.  **Fase de Ingest√£o e Indexa√ß√£o:**
    *   Come√ßa com os seus **Documentos PDF**, que cont√™m as informa√ß√µes que o chatbot deve usar.
    *   Estes documentos passam por um **Processamento de Dados** onde s√£o lidos e divididos em peda√ßos menores (chunks).
    *   Cada peda√ßo de texto √© transformado em um **vetor num√©rico** utilizando um **Modelo de Embedding** dedicado. Esse vetor captura o significado sem√¢ntico do texto.
    *   Os vetores (embeddings) s√£o ent√£o armazenados e indexados no **Azure AI Search**, criando um **√çndice Vetorial** otimizado para buscas de similaridade.

2.  **Fase de Consulta (RAG - Retrieval Augmented Generation):**
    *   Quando o **Usu√°rio** faz uma **Pergunta**, essa pergunta tamb√©m √© transformada em um vetor num√©rico usando o **mesmo Modelo de Embedding**.
    *   Este vetor da pergunta √© usado para realizar uma **Busca Vetorial** no **√çndice Vetorial** do Azure AI Search, procurando pelos trechos de documentos cujos vetores s√£o mais semelhantes ao vetor da pergunta.
    *   Os **Trechos Relevantes** dos documentos encontrados s√£o recuperados.
    *   A **Pergunta do Usu√°rio original** e os **Trechos Relevantes** recuperados (que servem como **contexto**) s√£o enviados para um **Modelo de Linguagem Generativa (LLM)**, como o GPT-4.
    *   O **LLM** processa a pergunta *utilizando unicamente o contexto fornecido* pelos trechos relevantes dos seus documentos para gerar a **Resposta Gerada e Contextualizada**.
    *   A resposta √© ent√£o apresentada de volta ao usu√°rio.

Todo esse processo √© orquestrado e executado dentro da plataforma **Azure AI Foundry**, que facilita o deploy dos modelos, o gerenciamento do √≠ndice de busca e a cria√ß√£o do playground ou web app para intera√ß√£o. Esta abordagem garante que as respostas do chatbot sejam precisas e diretamente fundamentadas no conte√∫do dos seus pr√≥prios documentos, n√£o apenas no conhecimento geral do LLM.

